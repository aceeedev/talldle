{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5278771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0e6dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 906 entries from CSV\n",
      "Output directory: data/images\n",
      "Overwrite directory: data/image overwrites\n"
     ]
    }
   ],
   "source": [
    "# Configuration: Read CSV and setup output directory\n",
    "df = pd.read_csv('data/final_data.csv')\n",
    "output_dir = 'data/images'\n",
    "overwrite_dir = 'data/image overwrites'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} entries from CSV\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Overwrite directory: {overwrite_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280ac842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert Wikipedia thumbnail URL to original image URL\n",
    "def get_original_wikimedia_url(thumbnail_url):\n",
    "    \"\"\"Convert Wikipedia thumbnail URL to original image URL\"\"\"\n",
    "    if 'upload.wikimedia.org' in thumbnail_url and '/thumb/' in thumbnail_url:\n",
    "        # Remove query parameters first\n",
    "        url = thumbnail_url.split('?')[0]\n",
    "        \n",
    "        # Format:   https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Example.jpg/198px-Example.jpg\n",
    "        # Original: https://upload.wikimedia.org/wikipedia/commons/a/ab/Example.jpg\n",
    "        \n",
    "        # Split on /thumb/ to separate base from path\n",
    "        if '/thumb/' in url:\n",
    "            base, path_with_size = url.split('/thumb/', 1)\n",
    "            # Find the last '/' which separates the full path from the sized filename\n",
    "            last_slash = path_with_size.rfind('/')\n",
    "            if last_slash != -1:\n",
    "                # The part before last slash is the full path including original filename\n",
    "                # e.g., \"a/ab/Example.jpg\"\n",
    "                full_path = path_with_size[:last_slash]\n",
    "                sized_filename = path_with_size[last_slash + 1:]\n",
    "                \n",
    "                # Remove size prefix (e.g., \"198px-\", \"640px-\") from sized filename to get original\n",
    "                dash_idx = sized_filename.find('-')\n",
    "                if dash_idx != -1:\n",
    "                    size_part = sized_filename[:dash_idx]\n",
    "                    # Check if it's a size prefix like \"198px\" or \"640px\"\n",
    "                    if size_part.replace('px', '').isdigit():\n",
    "                        # The original filename is after the size prefix\n",
    "                        original_filename = sized_filename[dash_idx + 1:]\n",
    "                    else:\n",
    "                        # No size prefix, use as-is\n",
    "                        original_filename = sized_filename\n",
    "                else:\n",
    "                    original_filename = sized_filename\n",
    "                \n",
    "                # Reconstruct original URL: base + / + full_path (which already includes the filename)\n",
    "                # Actually, full_path already contains the original filename, so we can use it directly\n",
    "                # But we need to make sure we're using the original filename, not the sized one\n",
    "                # So we replace the last component of full_path with original_filename\n",
    "                # Or simpler: full_path already IS the path with original filename\n",
    "                # So original_url = base + / + full_path\n",
    "                original_url = f\"{base}/{full_path}\"\n",
    "                return original_url\n",
    "    \n",
    "    return thumbnail_url\n",
    "\n",
    "# Function: Download and process image\n",
    "def download_and_process_image(image_url, output_path):\n",
    "    \"\"\"Download image, crop to square, resize to 128x128, and save\"\"\"\n",
    "    try:\n",
    "        # Convert Wikipedia thumbnail URLs to original image URLs to avoid 429 errors\n",
    "        if 'upload.wikimedia.org' in image_url:\n",
    "            image_url = get_original_wikimedia_url(image_url)\n",
    "        \n",
    "        # Download the image with User-Agent header (required for Wikipedia)\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(image_url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Open image from bytes\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # Convert to RGB if necessary (handles RGBA, P, etc.)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Get dimensions\n",
    "        width, height = img.size\n",
    "        \n",
    "        # Crop to square (centered horizontally, top-aligned vertically)\n",
    "        if width > height:\n",
    "            # Landscape: crop left and right\n",
    "            left = (width - height) // 2\n",
    "            right = left + height\n",
    "            img = img.crop((left, 0, right, height))\n",
    "        elif height > width:\n",
    "            # Portrait: crop from top\n",
    "            top = 0\n",
    "            bottom = width\n",
    "            img = img.crop((0, top, width, bottom))\n",
    "        # If already square, no cropping needed\n",
    "        \n",
    "        # Resize to 128x128\n",
    "        img = img.resize((128, 128), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Save as PNG\n",
    "        img.save(output_path, 'PNG')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fff8789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed!\n",
      "Successful: 43\n",
      "Failed: 0\n",
      "Skipped: 863\n",
      "Overwrites used: 1\n",
      "Total: 906\n"
     ]
    }
   ],
   "source": [
    "# Main processing loop\n",
    "successful = 0\n",
    "failed = 0\n",
    "skipped = 0\n",
    "overwrite_used = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_url = row['Image']\n",
    "    image_id = str(row['ID'])\n",
    "    output_path = os.path.join(output_dir, f\"{image_id}.png\")\n",
    "    \n",
    "    # Skip if already exists\n",
    "    if os.path.exists(output_path):\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Check if image exists in overwrites directory\n",
    "    overwrite_pattern = os.path.join(overwrite_dir, f\"{image_id}.*\")\n",
    "    overwrite_files = glob.glob(overwrite_pattern)\n",
    "    \n",
    "    if overwrite_files:\n",
    "        # Use the overwrite image as-is (copy directly)\n",
    "        overwrite_path = overwrite_files[0]\n",
    "        try:\n",
    "            shutil.copy2(overwrite_path, output_path)\n",
    "            successful += 1\n",
    "            overwrite_used += 1\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            # Fall through to download from URL\n",
    "            pass\n",
    "    \n",
    "    # Download and process from URL if no overwrite found\n",
    "    if download_and_process_image(image_url, output_path):\n",
    "        successful += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "\n",
    "print(f\"\\nCompleted!\")\n",
    "print(f\"Successful: {successful}\")\n",
    "print(f\"Failed: {failed}\")\n",
    "print(f\"Skipped: {skipped}\")\n",
    "print(f\"Overwrites used: {overwrite_used}\")\n",
    "print(f\"Total: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24268784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 906 images to ../src/talldle/public/images\n",
      "Images will be accessible at /images/{id}.png in your Next.js app\n"
     ]
    }
   ],
   "source": [
    "# Copy images to Next.js public folder\n",
    "public_images_dir = '../src/talldle/public/images'\n",
    "os.makedirs(public_images_dir, exist_ok=True)\n",
    "\n",
    "# Copy all images from data/images to public/images\n",
    "copied_count = 0\n",
    "for image_file in os.listdir(output_dir):\n",
    "    if image_file.endswith('.png'):\n",
    "        src_path = os.path.join(output_dir, image_file)\n",
    "        dst_path = os.path.join(public_images_dir, image_file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        copied_count += 1\n",
    "\n",
    "print(f\"Copied {copied_count} images to {public_images_dir}\")\n",
    "print(f\"Images will be accessible at /images/{{id}}.png in your Next.js app\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
